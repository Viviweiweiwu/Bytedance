{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 2
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from pymc import *\n",
    "from pymc.Matplot import plot as mplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 3
   },
   "outputs": [],
   "source": [
    "numquestions = 300 # number of test items being simulated\n",
    "numpeople = 10 # number of participants\n",
    "numthetas = 2 # number of latent proficiency variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 7
   },
   "outputs": [],
   "source": [
    "abilities = array([linspace(-1,1,numpeople), [1,-1] * int(numpeople/2)])\n",
    "numpy.save(\"abilities\", abilities)\n",
    "theta_initial = abilities\n",
    "correctness = zeros((numquestions, numpeople))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 1
   },
   "outputs": [],
   "source": [
    "# toggle the following to switch between generating from/learning latent variables\n",
    "# are we generating responses(1), or learning latent vars from pre-generated responses(0)?\n",
    "# (note that when not generating, \"correct.npy\" must have been generated with the same counts as above)\n",
    "generating = 0\n",
    "\n",
    "if generating:\n",
    "    # two ability params, one which alternates between -1 and 1 (across people)\n",
    "    #                       and another which moves smoothly from -1 to 1\n",
    "    abilities = array([linspace(-1,1,numpeople), [1,-1] * (numpeople/2)])#, list(linspace(-1,1,numpeople/2))+list(linspace(1,-1,numpeople/2))])\n",
    "    # abilities = array([linspace(-1,1,numpeople), linspace(1,-1,numpeople), linspace(0,0,numpeople)])\n",
    "    # abilities = array([[1]*(numpeople/3)+[0]*(numpeople/3)+[0]*(numpeople/3), [0]*(numpeople/3)+[1]*(numpeople/3)+[0]*(numpeople/3), [1]*(numpeople/3)+[0]*(numpeople/3)+[1]*(numpeople/3)])\n",
    "    numpy.save(\"abilities\", abilities)\n",
    "    theta_initial = abilities\n",
    "    correctness = zeros((numquestions, numpeople))\n",
    "else:\n",
    "    abilities = numpy.load(\"abilities.npy\")\n",
    "    theta_initial = zeros((numthetas, numpeople))\n",
    "    correctness = numpy.load(\"correct.npy\")\n",
    "\n",
    "# theta (proficiency params) are sampled from a normal distribution\n",
    "theta = Normal(\"theta\", mu=0, tau=1, value=theta_initial, observed=generating)\n",
    "\n",
    "# experimenting with various hyperparameters on the question discrimination parameters\n",
    "# a_mu_prior = Exponential(\"a_mu_prior\", beta=0.2, value=0)\n",
    "# a_mu_prior = Normal(\"a_mu_prior\", mu=1, tau=3, value=1)\n",
    "# TODO: use inverse gamma as prior, at least for tau; makes weaker assumptions\n",
    "\n",
    "# question-parameters (IRT params) are sampled from normal distributions (though others were tried)\n",
    "# (note that the mean for the discrimination parameters isn't 0, since in general questions will be somewhat diagnostic)\n",
    "a = Normal(\"a\", mu=1, tau=1, value=[[0.0] * numthetas] * numquestions)\n",
    "# a = Exponential(\"a\", beta=0.01, value=[[0.0] * numthetas] * numquestions)\n",
    "b = Normal(\"b\", mu=0, tau=1, value=[0.0] * numquestions)\n",
    "\n",
    "# take vectors theta/a/b, return a vector of probabilities of each person getting each question correct\n",
    "@deterministic\n",
    "def sigmoid(theta=theta, a=a, b=b):\n",
    "    bs = repeat(reshape(b, (len(b), 1)), numpeople, 1)\n",
    "    # print b.shape, a.shape, theta.shape\n",
    "    return 1.0 / (1.0 + exp(bs - dot(a, theta)))\n",
    "\n",
    "# take the probabilities coming out of the sigmoid, and flip weighted coins\n",
    "correct = Bernoulli('correct', p=sigmoid, value=correctness, observed=not generating)\n",
    "\n",
    "# create a pymc simulation object, including all the above variables\n",
    "m = MCMC([a,b,theta,sigmoid,correct])\n",
    "\n",
    "# run an interactive MCMC sampling session\n",
    "m.isample(iter=20000, burn=15000)\n",
    "\n",
    "# animated plot of theta values being sampled over time\n",
    "# lines are thetas (dotted are original thetas used to generate), across the x axis is people\n",
    "def plot_theta_trace():\n",
    "    stepsize = 20\n",
    "    trace = theta.trace()\n",
    "    for i in range(0, trace.shape[0], stepsize):\n",
    "        trace = theta.trace()\n",
    "        sample = trace[i:i+stepsize,:,:].mean(0).T\n",
    "        \n",
    "        # in case we're running the simulation in another thread, wait a bit for it to catch up\n",
    "        if sample[-3:,:].mean()==0:\n",
    "            pause(1)\n",
    "            continue\n",
    "        \n",
    "        clf()\n",
    "        plot(abilities.T, \"--\")\n",
    "        plot(sample)\n",
    "        title(i)\n",
    "        ylim((-3,3))\n",
    "        pause(0.01)\n",
    "\n",
    "if generating:\n",
    "    # while correct.get_logp() > -550: a.random(); b.random(); correct.random(); print correct.get_logp()\n",
    "    print correct.get_logp()\n",
    "    numpy.save(\"correct\", correct.get_value())\n",
    "    print \"Saved!\"\n",
    "else:\n",
    "    plot_theta_trace()\n",
    "\n",
    "# mplot(m)\n",
    "\n",
    "# draw a graph of the network structure and save it to a file\n",
    "# graph.graph(m).write_png(\"graph.png\")\n",
    "\n",
    "# matrix plot of each person's simulated % correct on each question\n",
    "# imshow(mean([correct.random() for i in range(1000)],0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "max_cell_id": 10
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
